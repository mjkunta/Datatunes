[
  {
    "objectID": "posts/we_are_live/index.html",
    "href": "posts/we_are_live/index.html",
    "title": "We are live Buana!",
    "section": "",
    "text": "Earlier this year, I wanted to start my data blog. My goals were clear, use it as repository to record what I have learnt so far and by writing, I will reinforce my understanding of the concepts. Since I had no intention of buliding a website from scratch, I had a popular website builder in mind. But the huddle was, how do I publish my documents from RStudio or VS code straight to my website.\nEnters Quarto. If you have you used RMarkdown, then you know how convenient it is to create a publication ready document. Quarto does this and supports multiple languages. The magic? You can create a fully functional blog website in just 15 minutes with Quarto. Now, whether I’m writing R, Python, or SQL documents, I can effortlessly commit them to my GitHub repository, and like clockwork, Netlify swoops in to pick up the updates and publish them on my website. Easy!\nIf this intrigues you, Albert Rapp has a very detailed guide on building a blog website with Quarto. If you want to set it up quickly, Beatriz has a quick and easy to follow guide. I used both, and my website is still in the works as I try to customize it further.\nWe are live buana, to Quarto creators, Thank You!"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Datatunes",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nReport Manipulation with R\n\n\n\n\n\n\n\nR\n\n\nReport Manipulation\n\n\n\n\n\n\n\n\n\n\n\nDec 14, 2023\n\n\n6 min\n\n\n\n\n\n\n\n\nQuery MS SQL and PostgreSQL from R/Quarto\n\n\n\n\n\n\n\nR\n\n\nQuarto\n\n\nMS SQL\n\n\nPostegreSQL\n\n\n\n\n\n\n\n\n\n\n\nNov 27, 2023\n\n\n7 min\n\n\n\n\n\n\n\n\nRenaming Columns with Python Dictionaries\n\n\n\n\n\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2023\n\n\n2 min\n\n\n\n\n\n\n\n\nWe are live Buana!\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "Hello, I’m Maangi Josiah, and I love all things data.\nI’m a Finance graduate from the University of Nairobi, Kenya with an appetite for data tools. I draw my dopamine from utilizing SQL, R, Power BI, and some Python. In this blog, I chronicle my data journey, sharing simple yet invaluable tricks I have encountered along the way."
  },
  {
    "objectID": "posts/Renaming Columns/index.html",
    "href": "posts/Renaming Columns/index.html",
    "title": "Renaming Columns with Python Dictionaries",
    "section": "",
    "text": "Import the required libraries\n\nimport pandas as pd\nimport os\n\n\n\nCreate a simple customer information data-frame\n\ndata = {\n    'given name': ['Josiah', 'Fred', 'Julie'],\n    'family name': ['Maangi', 'Juma', 'Musau'],\n    'phone':[25471234, 25472345,25473456],\n    'email': ['josiah@gml.com', 'fred@gml.com','julie@gml.com'],\n    'sex': ['M','M','F'],\n    'town': ['Nairobi', 'Kisumu', 'Mombasa']\n}\n\ncustomer_df = pd.DataFrame(data)\n\nHere is how our small data-frame looks:\n\ncustomer_df\n\n\n\n\n\n\n\n\ngiven name\nfamily name\nphone\nemail\nsex\ntown\n\n\n\n\n0\nJosiah\nMaangi\n25471234\njosiah@gml.com\nM\nNairobi\n\n\n1\nFred\nJuma\n25472345\nfred@gml.com\nM\nKisumu\n\n\n2\nJulie\nMusau\n25473456\njulie@gml.com\nF\nMombasa\n\n\n\n\n\n\n\n\n\nMake a copy of customer_df\n\ncustomer_df_copy = customer_df.copy()\n\n\n\nHow I want to Rename my columns\nI will rename my columns as below:\n\ngiven name to First Name\nfamily name to Last Name\ntown to City\n\n\n\nRename a single column\nTo rename columns, we use the rename function from pandas as follows.\nThe column we want to rename(given name) will be on the left, and the new name we want to assign to this column(Family Name) will be on the right. The two names should be separated by a colon.\nThe inplace = True argument means this change happen with our customer_df_copy.\n\ncustomer_df_copy.rename(columns = {'given name': 'Family Name'}, inplace = True)\n\n\n\nRename multiple columns at once\n\ncustomer_df_copy.rename(columns = {'given name': 'Family Name', 'town': 'City'}, inplace = True)\n\n\n\nCreate a dictionary of column mappings from an excel/csv file\nImagine a scenario where you have to rename about 15 columns every time you receive files from a given customers. Using the above approach is not only manual but prone to errors. Since this is a repetitive process;\n\nI will create a file with customer - company column mappings,\nconvert it into a dictionary, and\nuse it to rename files as below.\n\n\n\n\nclient to company column mapping\n\n\nCode\n\n# reading in my column mapping file\nmapping = pd.read_excel(r\"C:\\Users\\ADMIN\\Downloads\\col_mapping.xlsx\")\n\n# creating a data dictionary\ncol_mapping_dict = mapping.set_index('customer_details')['company_mapping'].to_dict()\n\n\n\nRename using provided column mappings\n\n# I will make a copy of my customer_df again\nrenamed_df = customer_df.copy()\n\n#then rename it\nrenamed_df.rename(columns = col_mapping_dict, inplace = True)\n\nHere is a view of our customer_df vs our renamed_df.\n\n\nTable 1: Master to renamed\n\n\n\n\n(a) customer_df\n\n\n\n\n\n\n\n\n\n\ngiven name\nfamily name\nphone\nemail\nsex\ntown\n\n\n\n\nJosiah\nMaangi\n25471234\njosiah@gml.com\nM\nNairobi\n\n\nFred\nJuma\n25472345\nfred@gml.com\nM\nKisumu\n\n\nJulie\nMusau\n25473456\njulie@gml.com\nF\nMombasa\n\n\n\n\n\n\n(b) renamed_df\n\n\n\n\n\n\n\n\n\n\nFirst Name\nLast Name\nPhone No\nEmail address\nGender\nCity\n\n\n\n\nJosiah\nMaangi\n25471234\njosiah@gml.com\nM\nNairobi\n\n\nFred\nJuma\n25472345\nfred@gml.com\nM\nKisumu\n\n\nJulie\nMusau\n25473456\njulie@gml.com\nF\nMombasa"
  },
  {
    "objectID": "posts/Combining CSV and Excel files in R/index.html",
    "href": "posts/Combining CSV and Excel files in R/index.html",
    "title": "Combining Files with R",
    "section": "",
    "text": "In this short blog post, I will show you how to combine multiple csv and excel files using R. I will focus on the following file structures:\n\nMultiple csv/excel files.\nMultiple Excel files with multiple tabs\nAn Excel workbook with tabs(sheets) holding similar information.\n\n\nLoad the required libraries:\n\n# first let create a list of our libraries, assuming all are installed\nlibs &lt;- c('rio', 'tidyverse', 'readxl', 'writexl','DT') \n\n# load the libraries\ninvisible(lapply(libs,library, character.only = T))\n\n\nCombining Multiple csv & excel files\nFirst, I will set my working directory to downloads folder since my target folder(file_to_combine) with files I want to combine is under downloads folder.\nHere is a screenshot of my files_to_combine folder and it’s contents.\n\nNB: There are better ways of working with file paths, but I wanted to make this easy to follow.\n\n# path to the folder\nfiles_to_combine &lt;- \"C:\\\\Users\\\\ADMIN\\\\Downloads\\\\files_to_combine\"\n\n# combine csv files in files_to_combine folder\ncombined_csvs &lt;- dir(files_to_combine,full.names = TRUE, pattern = \"csv\") |&gt;  \n  purrr::map_df(read_csv)\n\n# combine xlsx files in files_to_combine folder\ncombined_xlsx &lt;- dir(files_to_combine,full.names = TRUE, pattern = \"xlsx\") |&gt;  \n  purrr::map_df(read_excel)\n\n\n\nCombining a specific tab(sales) from multiple Excels workbooks\nLet’s assume you work for a company with branches across multiple cities in the world. And every month, the sales department receives an Excel workbook from each city with 3 tabs - orders, sales, and products. To quickly get the total sales, you have to consolidate data from the sales tab(sheet) from all files. This hypothetical, such a company would definitely maintain a sales database.\n\n\n# first, you will pass in the folder name \"sale_data\" to dir() as shown\n# second, you can include the pattern argument in dir() as we did above if your folder has other files other than Excel.\n# in the map_df, call the read_excel function followed by the sheetname using sheet as shown.\n\nsales_data &lt;- \"C:\\\\Users\\\\ADMIN\\\\Documents\\\\sales_data\"\n\nsales_report &lt;- dir(sales_data,full.names = T) |&gt; \n  map_df(read_excel,sheet= \"sales\")\n\nSometimes, you may run into this error - can’t combine chr with dbl . This simply means column types are inconsistent across the files you are trying to combine. The below solution worked for me.\n\n# all I did is change columns types across all files to character type\nsales_report_2 &lt;- dir(sales_data, full.names = T) |&gt;  \n  map_dfr(~read_excel(.x,sheet = \"sales\" ) |&gt; \n  mutate(across(.fns = as.character))) |&gt;  \n  type_convert()\n\n\n\nCombining all tabs(sheets) from an Excel workbook\nAgain, let’s assume we have an Excel workbook called agent_sale with sales data. Each tab has sales made by a particular sales agent and you want to combine the sheets into a single list. This is straightforward using the rio package as demonstrated below.\n\n\n\nUsing rio package and rbind\n\n# since my file is in the downloads folder which is my set workdirectory, \n#I will call the import_list function from rio on it as follows and combine \n#the sheets with rbind.\n\n#path to excel_workbook\nagent_sales &lt;- \"C:\\\\Users\\\\ADMIN\\\\Documents\\\\agent_sales.xlsx\"\n  \nagents_report &lt;- import_list(agent_sales, rbind = T)\n\n\n\nUsing readxl and tidyverse\nI will always prefer the above approach but if you want to know which sheet name each row of data is coming from, then this approach is exactly what you need.\n\n agents_report_2 &lt;- excel_sheets(agent_sales) |&gt;  \n  map_df(~mutate(read_xlsx(agent_sales, sheet = .x),\n                 agent_name = .x))\n\n\n# make a a table of the agent_report_2 and filter for any agent\ndatatable(agents_report_2, filter = 'top')"
  },
  {
    "objectID": "posts/email_cleaning/index.html",
    "href": "posts/email_cleaning/index.html",
    "title": "Email Cleaning",
    "section": "",
    "text": "This how to do it.\n\n2 + 2\n\n[1] 4"
  },
  {
    "objectID": "posts/Query DBs from R_Quarto/index.html",
    "href": "posts/Query DBs from R_Quarto/index.html",
    "title": "Query MS SQL and PostgreSQL from R/Quarto",
    "section": "",
    "text": "I have been using Quarto in RStudio for a few months now and I am captivated by it’s features. The ability to seamlessly execute SQL queries directly from SQL code chunks and saving results as R data frames is compelling. This connection is valuable when you want to leverage R’s data manipulations capabilities especially the tidyverse packages. We will explore a few examples in the next blog.\nFor now, let’s focus on establishing connections to and querying the following SQL databases:\n\nMS SQL Server\nPostegreSQL\n\n\nLoad the Required Libraries:\nMy preferred approach needs installation of only two packages. That is: ODBC and DBI. Since I have already installed the two packages, I will go ahead and load them.\n\nlibrary(odbc) # provides drivers to connect to different SQL dialects\nlibrary(DBI)  # provides functions to interact with the database\n\n\n\nConnect to MS SQL Server\nI will begin by connecting to Microsoft SQL Server using the dbConnect function from the DBI package. This function allows for database user authentication and connection establishment. You will need to provide the Driver, Server, Database, UID, and PWD parameters to the dbConnect function. For MS SQL Server, the Server parameter corresponds to the Server name, UID corresponds to Login, and PWD corresponds to Password in the login details, as shown in the first screenshot below. To obtain the MS SQL Driver, navigate to the Drivers tab in the ODBC Data Sources window, as shown in the second screenshot. The driver name will depend on the MS SQL version you are using.\n\n\n\nMS SQL Login\n\n\n\n\n\nDrivers\n\n\nAfter passing in the required parameters to dbConnect, I will save my connection as mssql_con as shown below. Having established the connection, we are ready to query our MS SQL database.\n\nmssql_con &lt;- DBI::dbConnect(drv = odbc::odbc(),\n                      Driver = \"SQL Server\",\n                      Server = \"DESKTOP-CKPR726\",\n                      Database = \"Employees\"\n                      #UID = \"user\",\n                      #PWD = \"password\"\n                      ) \n\nOnce the above code runs, the connection will be established and it will be displayed in the connection pane of your RStudio. As you can see below, we have connected to Employees database, we can see the tables under it, and the column names under Employee_Info table.\n\n\n\n\n\n\n\nQuerying MS SQL Server\nOf course we can query from an R code chunk as below using dbGetQuery().\n\nquery &lt;- 'SELECT TOP 5 Full_Name, Age, Gender FROM Employee_Info'\n\nemployees_df &lt;- DBI::dbGetQuery(mssql_con, query)\n\nBut let’s focus on how to do this from a sql code chunk. In the SQL code chunk section, assign your connection variable to the connection parameter as shown below.\n\n\n\n\n\nAnd then run your queries as below. Our first query will check tables that exist in the Employee database.\n\nSELECT \n      name AS Table_Name\nFROM \n      Employees.sys.tables\n\n\n3 records\n\n\nTable_Name\n\n\n\n\nEmployee_Info\n\n\nJob_Desc\n\n\nComp_Info\n\n\n\n\n\nNext, we will run a query using GROUP BY and ROLL UP to get Female and Male Employees per country, Female and Male totals, and also all total employees.\n\n\nSELECT\n         COALESCE(Gender, 'Employees') AS Gender\n        ,COALESCE(Country, 'Total') AS Country\n        ,COUNT(Full_Name) AS Employee_Counts\nFROM \n        Employee_Info AS EI\nLEFT JOIN\n        Job_Desc AS JD\n        ON EI.Emp_ID = JD.Emp_ID\nWHERE\n        Country &lt;&gt; 'Kenya'\nGROUP BY\n        ROLLUP (Gender, Country)\n\n\n9 records\n\n\nGender\nCountry\nEmployee_Counts\n\n\n\n\nFemale\nBrazil\n60\n\n\nFemale\nChina\n98\n\n\nFemale\nUnited States\n313\n\n\nFemale\nTotal\n471\n\n\nMale\nBrazil\n65\n\n\nMale\nChina\n102\n\n\nMale\nUnited States\n271\n\n\nMale\nTotal\n438\n\n\nEmployees\nTotal\n909\n\n\n\n\n\n\n\nSave the Query Output\nYou’ll want to save the output of your query into a df that you can use in R.\nWe save the output by passing a variable name to the output.var option in the sql code chunk as shown below.\n\n\n\n\n\nAnd then run your query. The query output will be saved as employee_gender_per_ctry and it will be one of the variables in your environment window in RStudio.\n\n\nSELECT\n         COALESCE(Gender, 'Total') AS Gender\n        ,COALESCE(Country, 'all countries') AS Country\n        ,COUNT(Full_Name) AS Employee_Counts\nFROM \n        Employee_Info AS EI\nLEFT JOIN\n        Job_Desc AS JD\n        ON EI.Emp_ID = JD.Emp_ID\nWHERE\n        Country &lt;&gt; 'Kenya'\nGROUP BY\n        CUBE (Gender, Country)\n        \n\nHere is our stored query output.\n\nemployee_gender_per_ctry\n\n   Gender       Country Employee_Counts\n1  Female        Brazil              60\n2    Male        Brazil              65\n3   Total        Brazil             125\n4  Female         China              98\n5    Male         China             102\n6   Total         China             200\n7  Female United States             313\n8    Male United States             271\n9   Total United States             584\n10  Total all countries             909\n11 Female all countries             471\n12   Male all countries             438\n\n\n\n\nConnect to PostegreSQL\nFor postgreSQL, you will follow the same procedure as we did with MS SQL and pass in the login details provided by your Database administrator. In my case, I’m the superuser 😎. Since my database is hosted locally, my server will be localhost, UID = postgres and PWD = postgres. These are the defaults when you install postgreSQL. But I changed my PWD to maangi.\nThe most important thing will be knowing the driver to use. Accessing these details is slightly different from accessing the MS SQL driver. Follow the following steps:\n\nOn you windows laptop, you click the windows key + R.\nOn the window that pops up, type - odbcad32.exe\n\nClick ok and navigate to the Drivers tab and pick the appropriate driver name as shown below.\n\n\nHaving passed in all the required parameters to dbConnect, I will proceed to create a connection variable called postegresql_con.\n\n# Establish the connection\npostgresql_con &lt;- dbConnect(odbc::odbc(),\n Driver = \"PostgreSQL ODBC Driver(ANSI)\",\n Database = \"car_brands\",\n Server = \"localhost\",\n UID = \"postgres\",\n PWD = \"maangi\"\n)\n\nOn running the above connection query, if you navigate to the connections pane in your RStudio, you will see that a connection has been establisted to postgresSQL.\n\n\n\n\n\n\n\nQuerying PostgreSQL\nSince we have established a connection, we can now query postgreSQL straight from a SQL code chunk in quarto as below.\n\n\n\nSELECT * FROM cars\n\n\ncars\n\n   brand  model year\n1  Volvo  p1800 1968\n2    BMW     M1 1978\n3 Toyota Celica 1975\n\n\nThere is a second approach that we can use to connect to postgreSQL. In this case, we will need to install and load the RPostgres package. Most of the parameters we pass in are similar except for port which we didn’t provide in the first approach and driver which is not needed in this case.\n\n# load the required library\nlibrary(RPostgres)\n\n# Replace these values with your actual database credentials\n postgresql_con2 &lt;- dbConnect(RPostgres::Postgres(),\n  dbname = \"car_brands\",\n  user = \"postgres\",\n  password = \"maangi\",\n  host = \"localhost\",\n  port = 5432  # The default PostgreSQL port is 5432\n)\n\n\n\nDisconnect\nLastly, it’s a good practice to disconnect from you database when you are done querying it to free up your laptop resources.\n\n# disconnect from MS SQL\ndbDisconnect(mssql_con)\n\n# disconnect from MS SQL\ndbDisconnect(postgresql_con)\n\ndbDisconnect(postgresql_con2)"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "My CV",
    "section": "",
    "text": "Download current CV"
  },
  {
    "objectID": "posts/Renaming Columns/Query DBs from R_Quarto/index.html",
    "href": "posts/Renaming Columns/Query DBs from R_Quarto/index.html",
    "title": "Query MS SQL and PostgreSQL from R/Quarto",
    "section": "",
    "text": "I have been using Quarto in RStudio for a few months now and I am captivated by it’s features. The ability to seamlessly execute SQL queries directly from SQL code chunks and saving results as R data frames is compelling. This connection is valuable when you want to leverage R’s data manipulations capabilities especially the tidyverse packages. We will explore a few examples in the next blog.\nFor now, let’s focus on establishing connections to and querying the following SQL databases:\n\nMS SQL Server\nPostegreSQL\n\n\nLoad the Required Libraries:\nMy preferred approach needs installation of only two packages. That is: ODBC and DBI. Since I have already installed the two packages, I will go ahead and load them.\n\nlibrary(odbc) # provides drivers to connect to different SQL dialects\nlibrary(DBI)  # provides functions to interact with the database\n\nlibrary(tidyverse) # for data manipulation\n\n\n\nConnect to MS SQL Server\nI will begin by connecting to Microsoft SQL Server using the dbConnect function from the DBI package. This function allows for database user authentication and connection establishment. You will need to provide the Driver, Server, Database, UID, and PWD parameters to the dbConnect function. For MS SQL Server, the Server parameter corresponds to the Server name, UID corresponds to Login, and PWD corresponds to Password in the login details, as shown in the first screenshot below. To obtain the MS SQL Driver, navigate to the Drivers tab in the ODBC Data Sources window, as shown in the second screenshot. The driver name will depend on the MS SQL version you are using.\n\n\n\nMS SQL Login\n\n\n\n\n\nDrivers\n\n\nAfter passing in the required parameters to dbConnect, I will save my connection as mssql_con as shown below. Having established the connection, we are ready to query our MS SQL database.\n\nmssql_con &lt;- DBI::dbConnect(drv = odbc::odbc(),\n                      Driver = \"SQL Server\",\n                      Server = \"DESKTOP-CKPR726\",\n                      Database = \"Employees\"\n                      #UID = \"user\",\n                      #PWD = \"password\"\n                      ) \n\nOnce the above code runs, the connection will be established and it will be displayed in the connection pane of your RStudio. As you can see below, we have connected to Employees database, we can see the tables under it, and the column names under Employee_Info table.\n\n\n\n\n\n\n\nQuerying MS SQL Server\nOf course we can query from an R code chunk as below using dbGetQuery().\n\nquery &lt;- 'SELECT TOP 5 Full_Name, Age, Gender FROM Employee_Info'\n\nemployees_df &lt;- DBI::dbGetQuery(mssql_con, query)\n\nBut let’s focus on how to do this from a sql code chunk. In the SQL code chunk section, assign your connection variable to the connection parameter as shown below.\n\n\n\n\n\nAnd then run your queries as below. Our first query will check tables that exist in the Employee database.\n\nSELECT \n      name AS Table_Name\nFROM \n      Employees.sys.tables\n\n\n3 records\n\n\nTable_Name\n\n\n\n\nEmployee_Info\n\n\nJob_Desc\n\n\nComp_Info\n\n\n\n\n\nNext, we will run a query using GROUP BY and ROLL UP to get Female and Male Employees per country, Female and Male totals, and also all total employees.\n\n\nSELECT\n         COALESCE(Gender, 'Employees') AS Gender\n        ,COALESCE(Country, 'Total') AS Country\n        ,COUNT(Full_Name) AS Employee_Counts\nFROM \n        Employee_Info AS EI\nLEFT JOIN\n        Job_Desc AS JD\n        ON EI.Emp_ID = JD.Emp_ID\nWHERE\n        Country &lt;&gt; 'Kenya'\nGROUP BY\n        ROLLUP (Gender, Country)\n\n\n9 records\n\n\nGender\nCountry\nEmployee_Counts\n\n\n\n\nFemale\nBrazil\n60\n\n\nFemale\nChina\n98\n\n\nFemale\nUnited States\n313\n\n\nFemale\nTotal\n471\n\n\nMale\nBrazil\n65\n\n\nMale\nChina\n102\n\n\nMale\nUnited States\n271\n\n\nMale\nTotal\n438\n\n\nEmployees\nTotal\n909\n\n\n\n\n\n\n\nSave the Query Output\nYou’ll want to save the output of your query into a df that you can use in R.\nWe save the output by passing a variable name to the output.var option in the sql code chunk as shown below.\n\n\n\n\n\nAnd then run your query. The query output will be saved as employee_gender_per_ctry and it will be one of the variables in your environment window in RStudio.\n\n\nSELECT\n         COALESCE(Gender, 'Total') AS Gender\n        ,COALESCE(Country, 'all countries') AS Country\n        ,COUNT(Full_Name) AS Employee_Counts\nFROM \n        Employee_Info AS EI\nLEFT JOIN\n        Job_Desc AS JD\n        ON EI.Emp_ID = JD.Emp_ID\nWHERE\n        Country &lt;&gt; 'Kenya'\nGROUP BY\n        CUBE (Gender, Country)\n        \n\nHere is our stored query output.\n\nemployee_gender_per_ctry\n\n   Gender       Country Employee_Counts\n1  Female        Brazil              60\n2    Male        Brazil              65\n3   Total        Brazil             125\n4  Female         China              98\n5    Male         China             102\n6   Total         China             200\n7  Female United States             313\n8    Male United States             271\n9   Total United States             584\n10  Total all countries             909\n11 Female all countries             471\n12   Male all countries             438\n\n\n\n\nConnect to PostegreSQL\nFor postgreSQL, you will follow the same procedure as we did with MS SQL and pass in the login details provided by your Database administrator. In my case, I’m the superuser 😎. Since my database is hosted locally, my server will be localhost, UID = postgres and PWD = postgres. These are the defaults when you install postgreSQL. But I changed my PWD to maangi.\nThe most important thing will be knowing the driver to use. Accessing these details is slightly different from accessing the MS SQL driver. Follow the following steps:\n\nOn you windows laptop, you click the windows key + R.\nOn the window that pops up, type - odbcad32.exe\n\nClick ok and navigate to the Drivers tab and pick the appropriate driver name as shown below.\n\n\nHaving passed in all the required parameters to dbConnect, I will proceed to create a connection variable called postegresql_con.\n\n# Establish the connection\npostgresql_con &lt;- dbConnect(odbc::odbc(),\n Driver = \"PostgreSQL ODBC Driver(ANSI)\",\n Database = \"car_brands\",\n Server = \"localhost\",\n UID = \"postgres\",\n PWD = \"maangi\"\n)\n\nOn running the above connection query, if you navigate to the connections pane in your RStudio, you will see that a connection has been establisted to postgresSQL.\n\n\n\n\n\n\n\nQuerying PostgreSQL\nSince we have established a connection, we can now query postgreSQL straight from a SQL code chunk in quarto as below.\n\n\n\nSELECT * FROM cars\n\n\ncars\n\n   brand  model year\n1  Volvo  p1800 1968\n2    BMW     M1 1978\n3 Toyota Celica 1975\n\n\nThere is a second approach that we can use to connect to postgreSQL. In this case, we will need to install and load the RPostgres package. Most of the parameters we pass in are similar except for port which we didn’t provide in the first approach and driver which is not needed in this case.\n\n# load the required library\nlibrary(RPostgres)\n\n# Replace these values with your actual database credentials\n postgresql_con2 &lt;- dbConnect(RPostgres::Postgres(),\n  dbname = \"car_brands\",\n  user = \"postgres\",\n  password = \"maangi\",\n  host = \"localhost\",\n  port = 5432  # The default PostgreSQL port is 5432\n)\n\n\n\nDisconnect\nLastly, it’s a good practice to disconnect from you database when you are done querying it to free up your laptop resources.\n\n# disconnect from MS SQL\ndbDisconnect(mssql_con)\n\n# disconnect from MS SQL\ndbDisconnect(postgresql_con)\n\ndbDisconnect(postgresql_con2)"
  },
  {
    "objectID": "posts/Report manipulation/nest dplyr.html",
    "href": "posts/Report manipulation/nest dplyr.html",
    "title": "Report Manipulation with R",
    "section": "",
    "text": "Scenario\nYou have been asked to pull a report of all employees and their respective departments from a database. The user wants this report in an Excel workbook with each department and employees under it on a separate sheet. Assuming we have Accounting, Finance, and Marketing departments, our Excel workbook should have 3 sheets(tabs) representing the 3 departments and their respective employees.\nYou can pull these reports one by one and add them to an Excel workbook since they are just 3. But what if there are 6 or more departments, that approach will be ineffective, manual, and annoyingly repetitive. Well, we can do pull a single report and easily manipulate it with tidyverse and openxlsx functions.\nLoad the required packages:\n\npacman::p_load(odbc, DBI, tidyverse, writexl, openxlsx)\n\nTo manipulate our report into a workbook with sheets for each department, we will do the following.\n\nPull a single report with all employees and their respective departments and save it.\nCreate a workbook\nApply the nest_by function from dplyr to our report and nest by Department.\nAdd sheets to our workbook. We will use department names as our sheet names.\nWrite data into each sheets(Department)\nSave your workbook\n\nA primer on nest_by()\nFirst, I will create a simple df and see what happens to it when we apply the nest_by function to it. Below is my simple members df with columns: name, country, and avg_sleep_hours.\n\n# create a simple data frame and call it members\nname &lt;- c('Julie', 'Maangi', 'Kevin', 'Mercy', 'Nick', 'Salim') \ncountry &lt;- c('Kenya', 'Kenya', 'Uganda', 'Uganda', 'Tanzania', 'Tanzania')\navg_sleep_hours &lt;- c(8, 7, 7, 9, 6, 9)\nmembers &lt;- data.frame(name, country, avg_sleep_hours)\n\nmembers\n\n    name  country avg_sleep_hours\n1  Julie    Kenya               8\n2 Maangi    Kenya               7\n3  Kevin   Uganda               7\n4  Mercy   Uganda               9\n5   Nick Tanzania               6\n6  Salim Tanzania               9\n\n\nNext, let us see what happens when we nest_by the country column on the members df.\nnest_by works the same way as group_by except that it turns our data frame into an object with two columns in this case. The first column is the categories we are nesting by - country and will display the unique categories as our rows. The second column is data from other columns. In summary, all details for members from Kenya will be bundled into a single row, ditto those from Uganda and Tanzania as shown below. With this formating, we can easily write our data for each country into separate sheet.\nSetting .keep = TRUE in the code allows us to keep the column(s) we are nesting by.\n\n members |&gt;\n  nest_by(country, .keep = TRUE)\n\n\n\n\n\n\n\n\nApply the concept to our use case\nCreate a database connection and pull our report\n\nmssql_con &lt;- DBI::dbConnect(drv = odbc::odbc(),\n                      Driver = \"SQL Server\",\n                      Server = \"DESKTOP-CKPR726\",\n                      Database = \"Employees\"\n                      #UID = \"user\",\n                      #PWD = \"password\"\n                      ) \n\nBefore pulling the report, we can check how many distinct Departments we have. So we expect 7 sheets in our workbook.\n\nSELECT\n  DISTINCT\n      Department\nFROM\n      Job_Desc\n\n\n7 records\n\n\nDepartment\n\n\n\n\nMarketing\n\n\nSales\n\n\nEngineering\n\n\nIT\n\n\nHuman Resources\n\n\nFinance\n\n\nAccounting\n\n\n\n\n\nLet’s pull a report of all employees and their departments. I will save it as employees_per_dept\n\n\nSELECT\n          Full_Name\n        , Gender\n        , Age\n        , Country\n        , Department\n        , Business_Unit\nFROM \n          Employee_Info AS EI\nLEFT JOIN\n          Job_Desc AS JD\n      ON  EI.Emp_ID = JD.Emp_ID\nWHERE Department IS NOT NULL\n\nCreate a workbook, apply the nest_by function, add sheets to our workbook, write data into the respective sheets, and save the workbook.\n\n# initialize the workbook\n\nemployees_workbook &lt;- createWorkbook()\n\n# apply nest_by to our report\nemployees_per_dept |&gt; \n  dplyr::nest_by(Department, .keep = TRUE) |&gt; \n  \n# add worksheets for each department to our workbook\n  dplyr::mutate(\n    addWorksheet(employees_workbook, paste0(Department, '_Dept')),\n    \n# write data into the respective worksheets(Departments)\n    writeData(employees_workbook, paste0(Department,'_Dept'), data,)\n  ) \n   \n# save workbook\nsaveWorkbook(employees_workbook, 'employees_per_dept.xlsx', overwrite = TRUE)\n\nAnd we will get our workbook with all the sheets(Departments) as shown below.\n\n\n\n\n\n\n\nReport Customization\nWe can customize our report by adding alignment, font style, color, tabcolour, and gridlines. There also many styles one can apply.\n\n# define the style of my sheets\nhs1 &lt;- createStyle(\n  fgFill = \"#DCE6F1\", halign = \"CENTER\", textDecoration = \"italic\",\n  border = \"Bottom\"\n)\n\n\nwb2 &lt;- createWorkbook()\n\n# write into the workbook\nemployees_per_dept |&gt; \n  dplyr::nest_by(Department, .keep = TRUE) |&gt; \n  \n# add worksheets for each department to our workbook\n  dplyr::mutate(\n    addWorksheet(wb2, \n                 paste0(Department, '_Dept'), \n                 gridLines = FALSE, \n                 tabColour = '#00008b'),\n    \n# write data into the respective worksheets(Departments)\n    writeData(wb2, \n              paste0(Department,'_Dept'), \n              data, \n              headerStyle = hs1)\n  ) \n   \n# save workbook\nsaveWorkbook(wb2, 'employees_per_dept2.xlsx', overwrite = TRUE)\n\n\n\n\n\n\nUp next, we will see how we can do this using python - with groupby from pandas and a few functions from openpyxl."
  }
]